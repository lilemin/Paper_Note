# Rethinking the Inception Architecture for Computer Vision
## Introduction
### 模型比较
Model | 结构 | 参数|
------|------|----
Inception| 复杂，难以调整 | AlexNet的十二分之一，计算成本较低
VGGNet | 简洁| AlexNet的三倍，计算成本较高
### 宗旨
- 目的：从描述一些一般原则和优化思想开始，以有效的方式扩展卷积网络
- 对象：不局限于Inception类型的网络，但其更容易观察，因为Inception类型构建块的通用结构足够灵活，可以自然地合并这些约束。
- 内容：通过大量使用降维和Inception模块的并行结构来实现，这允许减轻结构变化对邻近组件的影响
- 限制：应该遵守一些指导原则来保持模型的高质量。

## General Design Principles
- 未完成

## Factorizing Convolutions with Large Filter Size
### 分解到更小的卷积
**1. 原因**：

较大的卷积核往往会导致不成比例的昂贵的计算成本
- 与3×3×n的卷积相比，5×5×n的卷积核在含m个filter的输入数据体上的计算量要高（5×5）/（3×3）=2.78倍
- 5×5的卷积核，可以捕获更前面的层次中更远的单元激活*activation*中信号间的依赖性。因次卷积核尺寸的减小会导致较大的表现*expressiveness*成本

**2. 问题**
- 5×5卷积是否可以被具有相同输入尺寸和输出深度的参数较小的多层网络所取代？

**3. 分析**
- 事实：若放大5×5卷积的计算图， 每个输出就像是一个小型全连接网络，其在输入上滑动5×5的块（即卷积核上的权重）
- 理论：利用平移不变性，可通过两层的卷积结构来代替全连接的组件
- 实施：第一层是3×3卷积，第二层是在第一层的3×3输出网格之上的一个全连接层
- 结果：通过在输入激活网格上滑动这个小网络，用两层3×3卷积来替换5×5卷积（比较图4和5）
- 效果：通过相邻块之间共享权重明显减少了参数数量
- 结论：大于3×3的卷积核一般不常用，其可以简化为3×3卷积层序列
- 未完成

### 空间分解为不对称卷积
- 假设：是否将卷积核的尺寸再分解得更小，如2×2？
- 发现：n×n的卷积核不对称分解为1×n和n×1的效果更佳
- 结论：先后使用3×1卷积层和1×3卷积层（双层结构），相当于具有相同有效感受野的3×3卷积层
- 分析：如果输入和输出filter数量相等，将3×3卷积分解为双层结构的计算量可以降低33%;将3×3卷积分解为两个2×2卷积的计算两仅节省了11％
- 局限： 不对称分解结构在early layer的结果并不好，在特征尺寸中等（m×m的特征图，m在12至20之间）上的效果很好。可采用1×7和7×1的卷积层

### 利用辅助分类器
- 提出： 在Inception_v1中，首次提出辅助分类器的概念，用于改善非常深的网络的收敛
- 原理： 将有用的梯度传向较低的层次，使梯度可以立刻使用，并通过抵抗非常深的网络中梯度消失的问题，进而提高训练过程的收敛性
- 假设：
  + 辅助分类器有助于稳定地学习和提高收敛性
  + 辅助分类器起的是正则化的作用
- 证明：
  + 辅助分类器在训练早期并没有导致改善收敛，接近训练结束，辅助分支网络开始超越没有任何分支的网络的准确性，达到了更高的稳定水平
  + 底层的辅助分类器去除后，对网络并没有不利的影响。如果网络分支batch-normalized 或dropout层，主分类器的效果会更佳

### 有效地减少网格*grid*尺寸
- 背景：传统上，卷积网络会采用池化操作来缩小特征图的网格尺寸。为避免表示瓶颈*representational bottleneck*，
在应用最大值池化或平均值池化前，扩展网络的激活维度*activation dimension*
- 操作：从k个filters的d×d网格*grid*，得到2k个filters的d/2 × d/2网格， 首先需要计算2k个filters，步长为1的卷积计算，在采用额外的池化操作
- 分析：&2^2&




例如，开始有一个带有k个滤波器的d×d网格，如果我们想要达到一个带有2k个滤波器的d2×d2网格，我们首先需要用2k个滤波器计算步长为1的卷积，
然后应用一个额外的池化步骤。这意味着总体计算成本由在较大的网格上使用2d2k2次运算的昂贵卷积支配。一种可能性是转换为带有卷积的池化，
因此导致2(d2)2k2次运算，将计算成本降低为原来的四分之一。然而，由于表示的整体维度下降到(d2)2k，会导致表示能力较弱的网络（参见图9），
这会产生一个表示瓶颈。我们建议另一种变体，其甚至进一步降低了计算成本，同时消除了表示瓶颈（见图10），
而不是这样做。我们可以使用两个平行的步长为2的块：P和C。P是一个池化层（平均池化或最大池化）的激活，两者都是步长为2，其滤波器组连接如图10所示。
